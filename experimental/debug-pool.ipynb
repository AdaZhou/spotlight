{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/ipykernel/__main__.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.interactions import Interactions\n",
    "import pandas as pd\n",
    "from spotlight.evaluation import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from spotlight.factorization.representations import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.interactions import Interactions\n",
    "import pandas as pd\n",
    "from spotlight.evaluation import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from spotlight.factorization.representations import *\n",
    "import os\n",
    "import collections\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet, PoolNet\n",
    "\n",
    "input_config = os.environ\n",
    "\n",
    "hyperparameters = {\n",
    "    'loss': \"adaptive_hinge\",\n",
    "    'batch': 128,\n",
    "    'lr': 1e-3,\n",
    "    'l2': 1e-06,\n",
    "    'n_iter': 50,\n",
    "    'emb_dim': 128,\n",
    "    'type': 'pool',\n",
    "    \"layers\": [int(x) for x in \"256-128-64-1\".split(\"-\")],\n",
    "    \"nonlin\": 'tanh',\n",
    "    \"max_seq\": 50,\n",
    "    \"min_seq\": 2,\n",
    "    \"step\": 2,\n",
    "    \"fmax_seq\": 50\n",
    "}\n",
    "\n",
    "h = hyperparameters\n",
    "\n",
    "if 'SUFFIX' in input_config:\n",
    "    suffix = input_config['SUFFIX']\n",
    "else:\n",
    "    suffix = \"1\"\n",
    "\n",
    "if 'LOSS' in input_config:\n",
    "    h['loss'] = input_config['LOSS']\n",
    "\n",
    "if 'LR' in input_config:\n",
    "    h['lr'] = float(input_config['LR'])\n",
    "\n",
    "if 'L2' in input_config:\n",
    "    h['l2'] = float(input_config['L2'])\n",
    "\n",
    "if 'MOM' in input_config:\n",
    "    h['mom'] = float(input_config['MOM'])\n",
    "else:\n",
    "    h['mom'] = 0.9\n",
    "\n",
    "if 'NEGSAMPLES' in input_config:\n",
    "    h['neg'] = int(input_config['NEGSAMPLES'])\n",
    "else:\n",
    "    h['neg'] = 5\n",
    "\n",
    "if 'BATCH' in input_config:\n",
    "    h['batch'] = int(input_config['BATCH'])\n",
    "\n",
    "h['amsgrad'] = False\n",
    "if 'AMSGRAD' in input_config:\n",
    "    h['amsgrad'] = (input_config['AMSGRAD'] == 'True')\n",
    "\n",
    "h['adamw'] = False\n",
    "if 'ADAMW' in input_config and input_config['ADAMW']:\n",
    "    h['adamw'] = (input_config['ADAMW'] == 'True')\n",
    "\n",
    "if 'EMBDIM' in input_config:\n",
    "    h['emb_dim'] = int(input_config['EMBDIM'])\n",
    "\n",
    "if \"LAYERS\" in input_config:\n",
    "    h[\"layers\"] = [int(x) for x in input_config['LAYERS'].split(\"-\")]\n",
    "\n",
    "if \"NONLIN\" in input_config:\n",
    "    h[\"nonlin\"] = input_config['NONLIN']\n",
    "\n",
    "if \"MAXSEQ\" in input_config:\n",
    "    h[\"max_seq\"] = int(input_config[\"MAXSEQ\"])\n",
    "\n",
    "if \"MINSEQ\" in input_config:\n",
    "    h[\"min_seq\"] = int(input_config[\"MINSEQ\"])\n",
    "\n",
    "if \"STEPSIZE\" in input_config:\n",
    "    h[\"step\"] = int(input_config[\"STEPSIZE\"])\n",
    "\n",
    "if \"FILTERSEQ\" in input_config:\n",
    "    h[\"fmax_seq\"] = int(input_config[\"FILTERSEQ\"])\n",
    "\n",
    "betas = (h['mom'], 0.999)\n",
    "use_cuda = True\n",
    "\n",
    "tensorboard_base_dir = \"sruns\"\n",
    "model_store_dir = \"smodels\"\n",
    "n_iters = 50\n",
    "# loss=\"adaptive_hinge\"\n",
    "\n",
    "log_loss_interval = 1000\n",
    "log_eval_interval = 20000\n",
    "\n",
    "model_alias = \",\".join([k + \"=\" + str(v) for k, v in collections.OrderedDict(h).items()])\n",
    "model_alias = \"pool_\" + suffix + \"_\" + model_alias\n",
    "\n",
    "# train_data_path = \"s3a://tubi-playground-production/smistry/emb3/train-aug-28-phase1\"\n",
    "train_data_path = \"/home/ec2-user/emb3/data/train-aug-28-phase\" + suffix\n",
    "\n",
    "logging.basicConfig(filename=\"slogs/\" + model_alias + '.log',\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "max_sequence_length = h[\"max_seq\"]\n",
    "min_sequence_length = h[\"min_seq\"]\n",
    "step_size = h[\"step\"]\n",
    "\n",
    "\n",
    "original_train_data = pd.read_parquet(train_data_path)\n",
    "logger.info(\"Data is downloaded\")\n",
    "# train_data = original_train_data\n",
    "uvs = original_train_data.groupby(\"uindex\")[\"vindex\"].agg(list)\n",
    "train_data = original_train_data[original_train_data.uindex.isin(uvs[uvs.apply(lambda x: len(x)) <= h[\"fmax_seq\"]].index)]\n",
    "\n",
    "logger.info(\"Filtered train data..\")\n",
    "\n",
    "train_data[\"vindex\"] = train_data[\"vindex\"] + 1\n",
    "num_items = len(original_train_data[\"vindex\"].unique()) + 2\n",
    "interactions = Interactions(train_data[\"uindex\"].to_numpy(),\n",
    "                            train_data[\"vindex\"].to_numpy(),\n",
    "                            train_data[\"pct_cvt\"].to_numpy(),\n",
    "                            train_data[\"latest_watch_time\"].to_numpy(),\n",
    "                            num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "                            num_items=num_items)\n",
    "\n",
    "\n",
    "# if \"1500K\" in suffix:\n",
    "#     logger.info(\"Increasing step size and max_sequence_length\")\n",
    "#     step_size = 2\n",
    "#     min_sequence_length = 2\n",
    "#     max_sequence_length = 50\n",
    "\n",
    "train_seq = interactions.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                                     min_sequence_length=min_sequence_length,\n",
    "                                     step_size=step_size)\n",
    "\n",
    "logger.info(\"Data is loaded and converted to sequences..\")\n",
    "\n",
    "writer = SummaryWriter(log_dir='{}/{}'.format(tensorboard_base_dir, model_alias))\n",
    "writer.add_text('alias', model_alias, 0)\n",
    "writer.add_text('hyperparameters', str(h), 0)\n",
    "\n",
    "\n",
    "def notify_loss_completion(epoch_id, batch_id, loss, net, model):\n",
    "    # print(\"notify_loss_completion\")\n",
    "    writer.add_scalar(\"Batch/loss\", loss, batch_id)\n",
    "    logging.info('[Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\n",
    "\n",
    "\n",
    "def notify_batch_eval_completion(epoch_id, batch_id, loss, net, model):\n",
    "    # print(\"notify_batch_eval_completion\")\n",
    "    m = 1\n",
    "\n",
    "\n",
    "def notify_epoch_completion(epoch_num, total_loss, net, model):\n",
    "    # print(\"notify_epoch_completion\")\n",
    "    writer.add_scalar(\"Epoch/loss\", total_loss, epoch_num)\n",
    "    pairs_ndcg = nn_pairs_ndcg_score(net)\n",
    "    writer.add_scalar(\"Epoch/pairs_ndcg\", pairs_ndcg, epoch_num)\n",
    "    #     hit_ratio, ndcg = evaluate_hit_ratio_and_ndcg(model)\n",
    "    #     writer.add_scalar(\"Epoch/HR\", hit_ratio, epoch_num)\n",
    "    #     writer.add_scalar(\"Epoch/NDCG\", ndcg, epoch_num)\n",
    "    hit_ratio, ndcg = -1, -1\n",
    "    logging.info('******** [Epoch {}]  Embs NDCG {:.4f}, Hit Ratio: {:.4f}, NDCG: {:.4f}'.format(epoch_num,\n",
    "                                                                                                 pairs_ndcg,\n",
    "                                                                                                 hit_ratio,\n",
    "                                                                                                 ndcg))\n",
    "    torch.save(net, model_store_dir + \"/\" + model_alias + \"-\" + str(epoch_num))\n",
    "    net.train()\n",
    "\n",
    "\n",
    "if \"BASE_DIR\" not in os.environ:\n",
    "    os.environ[\"BASE_DIR\"] = \"/home/ec2-user/emb3\"\n",
    "\n",
    "random_state = np.random.RandomState(100)\n",
    "\n",
    "net = PoolNet(num_items,\n",
    "              embedding_dim=h['emb_dim'],\n",
    "              layers=h[\"layers\"],\n",
    "              nonlinearity=h['nonlin'])\n",
    "\n",
    "model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                              representation=net,\n",
    "                              batch_size=h['batch'],\n",
    "                              learning_rate=h['lr'],\n",
    "                              l2=h['l2'],\n",
    "                              n_iter=h['n_iter'],\n",
    "                              embedding_dim=h['emb_dim'],\n",
    "                              use_cuda=use_cuda,\n",
    "                              random_state=random_state,\n",
    "                              notify_loss_completion=notify_loss_completion,\n",
    "                              notify_batch_eval_completion=notify_batch_eval_completion,\n",
    "                              notify_epoch_completion=notify_epoch_completion,\n",
    "                              log_loss_interval=5000,\n",
    "                              log_eval_interval=20000,\n",
    "                              amsgrad=h['amsgrad'],\n",
    "                              adamw=h['adamw'],\n",
    "                              betas=betas,\n",
    "                              num_negative_samples=h['neg'])\n",
    "\n",
    "logger.info(\"Model is initialized, now fitting..\")\n",
    "#model.fit(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = train_seq.sequences.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_tensor = gpu(torch.from_numpy(sequences),\n",
    "                                       True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.torch_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gpu(net, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolNet(\n",
       "  (item_embeddings): ScaledEmbedding(17535, 128, padding_idx=0)\n",
       "  (item_biases): ZeroEmbedding(17535, 1, padding_idx=0)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): TimeDistributed(\n",
       "      (module): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (1): TimeDistributed(\n",
       "      (module): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (2): TimeDistributed(\n",
       "      (module): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 50])\n",
      "torch.Size([64, 50])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [8192 x 100], m2: [256 x 128] at /tmp/pip-req-build-58y_cjjl/aten/src/THC/generic/THCTensorMathBlas.cu:273",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b2a37932e426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     positive_prediction = net(user_representation,\n\u001b[0;32m---> 15\u001b[0;31m                                     sequence_var)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adaptive_hinge'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/emb3/spotlight/spotlight/sequence/representations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user_representations, targets)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/emb3/spotlight/spotlight/sequence/representations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mx_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (samples * timesteps, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# We have to reshape Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [8192 x 100], m2: [256 x 128] at /tmp/pip-req-build-58y_cjjl/aten/src/THC/generic/THCTensorMathBlas.cu:273"
     ]
    }
   ],
   "source": [
    "self = model\n",
    "for minibatch_num, batch_sequence in enumerate(minibatch(sequences_tensor,\n",
    "                                                             batch_size=64)):\n",
    "    net.train()\n",
    "    net.train()\n",
    "    sequence_var = batch_sequence\n",
    "\n",
    "    user_representation, _ = net.user_representation(\n",
    "        sequence_var\n",
    "    )\n",
    "    \n",
    "    print(user_representation.shape)\n",
    "    print(sequence_var.shape)\n",
    "    positive_prediction = net(user_representation,\n",
    "                                    sequence_var)\n",
    "\n",
    "    if self._loss == 'adaptive_hinge':\n",
    "        negative_prediction = self._get_multiple_negative_predictions(\n",
    "            sequence_var.size(),\n",
    "            user_representation,\n",
    "            n=self._num_negative_samples)\n",
    "    else:\n",
    "        negative_prediction = self._get_negative_prediction(sequence_var.size(),\n",
    "                                                            user_representation)\n",
    "    \n",
    "    print(\"Done\")\n",
    "    self._optimizer.zero_grad()\n",
    "\n",
    "    loss = self._loss_func(positive_prediction,\n",
    "                           negative_prediction,\n",
    "                           mask=(sequence_var != PADDING_IDX))\n",
    "    loss_val = loss.item()\n",
    "    epoch_loss += loss_val\n",
    "    interval_loss += loss_val\n",
    "\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ImplicitSequenceModel: PoolNet(\n",
       "  (item_embeddings): ScaledEmbedding(17540, 128, padding_idx=0)\n",
       "  (item_biases): ZeroEmbedding(17540, 1, padding_idx=0)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "suffix = \"1500K-with-3-vids\"\n",
    "train_data_path = \"/home/ec2-user/emb3/data/train-aug-28-phase\" + suffix\n",
    "original_train_data = pd.read_parquet(train_data_path)\n",
    "validate_neg_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-neg-flatten-aug-28-phase\" + suffix)\n",
    "validate_pos_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-pos-flatten-aug-28-phase\" + suffix)\n",
    "validation_train_data = original_train_data[original_train_data[\"uindex\"].isin(validate_pos_flatten_vids.uindex.tolist())]\n",
    "validation_train_data[\"vindex\"] = validation_train_data[\"vindex\"] + 1\n",
    "interactions = Interactions(validation_train_data[\"uindex\"].to_numpy(),\n",
    "            validation_train_data[\"vindex\"].to_numpy(),\n",
    "            validation_train_data[\"pct_cvt\"].to_numpy(),\n",
    "            validation_train_data[\"latest_watch_time\"].to_numpy(),\n",
    "            num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "            num_items=len(original_train_data[\"vindex\"].unique()) + 2)\n",
    "\n",
    "max_sequence_len=100\n",
    "sequences = interactions.to_sequence(max_sequence_length=max_sequence_len, step_size=max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.torch_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda= True\n",
    "sqs = sequences.sequences[:5]\n",
    "sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'256-128-64-1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PoolNet(num_items,\n",
    "              embedding_dim=h['emb_dim'],\n",
    "              layers=h[\"layers\"],\n",
    "              nonlinearity=h['nonlin'])\n",
    "net = gpu(net, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolNet(\n",
       "  (item_embeddings): ScaledEmbedding(20000, 128, padding_idx=0)\n",
       "  (item_biases): ZeroEmbedding(20000, 1, padding_idx=0)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rp = net.user_representation(sequences_tensor)[1]\n",
    "vids=[1,3, 4,5,7]\n",
    "target_embedding = net.item_embeddings(gpu(torch.from_numpy(np.array(vids).reshape(-1, 1)).long(),use_cuda)).permute(0, 2, 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0523, 0.0517, 0.0528, 0.0537, 0.0521], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = gpu(torch.from_numpy(np.array(vids).reshape(-1, 1)), True)\n",
    "net(user_rp, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda= True\n",
    "sqs = sequences.sequences[:5]\n",
    "sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)\n",
    "user_rp = mm.user_representation(sequences_tensor)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
