{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"SUFFIX\"]= \"1500K-with-3-vids\"\n",
    "os.environ[\"BASE_DIR\"] = \"/home/ec2-user/emb3\"\n",
    "\n",
    "hyperparameters = {\n",
    "    'loss': \"adaptive_hinge\",\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 1e-3,\n",
    "    'l2': 1e-06,\n",
    "    'n_iter': 30,\n",
    "    'embedding_dim': 64\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.interactions import Interactions\n",
    "import pandas as pd\n",
    "from spotlight.evaluation import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from spotlight.factorization.representations import *\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.torch_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "mm = torch.load(\"/home/ec2-user/emb3/smodels/cnn_loss=adaptive_hinge,batch=128,lr=0.001,l2=1e-06,n_iter=50,emb_dim=128,type=cnn,mom=0.9,neg=3,amsgrad=True,adamw=False-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNNet(\n",
       "  (item_embeddings): ScaledEmbedding(17540, 128, padding_idx=0)\n",
       "  (item_biases): ZeroEmbedding(17540, 1, padding_idx=0)\n",
       "  (cnn_0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.51 ms\n"
     ]
    }
   ],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 408 µs\n"
     ]
    }
   ],
   "source": [
    "suffix = \"1500K-with-3-vids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.15 s\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"/home/ec2-user/emb3/data/train-aug-28-phase\" + suffix\n",
    "original_train_data = pd.read_parquet(train_data_path)\n",
    "validate_neg_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-neg-flatten-aug-28-phase\" + suffix)\n",
    "validate_pos_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-pos-flatten-aug-28-phase\" + suffix)\n",
    "validation_train_data = original_train_data[original_train_data[\"uindex\"].isin(validate_pos_flatten_vids.uindex.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.29 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "validation_train_data[\"vindex\"] = validation_train_data[\"vindex\"] + 1\n",
    "\n",
    "# sort_indices = np.lexsort((validation_train_data[\"latest_watch_time\"].tolist(), validation_train_data[\"uindex\"].tolist()))\n",
    "# vlist = validation_train_data.iloc[sort_indices].groupby(\"uindex\")[\"vindex\"].agg(list).reset_index()\n",
    "# vlist.to_parquet(os.environ['BASE_DIR'] + \"/data/\" + \"loo-validation-\" + suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "interactions = Interactions(validation_train_data[\"uindex\"].to_numpy(),\n",
    "            validation_train_data[\"vindex\"].to_numpy(),\n",
    "            validation_train_data[\"pct_cvt\"].to_numpy(),\n",
    "            validation_train_data[\"latest_watch_time\"].to_numpy(),\n",
    "            num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "            num_items=len(original_train_data[\"vindex\"].unique()) + 2)\n",
    "\n",
    "max_sequence_len=100\n",
    "sequences = interactions.to_sequence(max_sequence_length=max_sequence_len, step_size=max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.15 ms\n"
     ]
    }
   ],
   "source": [
    "#sequences.sequences\n",
    "use_cuda= True\n",
    "sqs = sequences.sequences[:5]\n",
    "sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)\n",
    "user_representation, _ = mm.user_representation(sequences_tensor)\n",
    "\n",
    "vids=[1,3, 4,5,7]\n",
    "\n",
    "vids_tensor = gpu(torch.from_numpy(np.array(vids).reshape(-1, 1)).long(),use_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.14 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5602, -0.0070,  1.3687,  1.3683,  2.3950], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.65 ms\n"
     ]
    }
   ],
   "source": [
    "mm(user_rp[1], vids_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.57 ms\n"
     ]
    }
   ],
   "source": [
    "layers = [256, 128, 64, 1]\n",
    "\n",
    "fc_layers =  None\n",
    "if layers and len(layers) > 0:\n",
    "    fc_layers = torch.nn.ModuleList()\n",
    "    for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "        fc_layers.append(torch.nn.Linear(in_size, out_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.5 ms\n"
     ]
    }
   ],
   "source": [
    "fc_layers = gpu(fc_layers, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.35 ms\n"
     ]
    }
   ],
   "source": [
    "fc_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.08 ms\n"
     ]
    }
   ],
   "source": [
    "vids=[1,3, 4,5,7]\n",
    "\n",
    "user_representations = user_rp\n",
    "target_embedding = mm.item_embeddings(gpu(torch.from_numpy(np.array(vids).reshape(-1, 1)).long(),use_cuda)).permute(0, 2, 1).squeeze()\n",
    "\n",
    "vector = torch.cat([user_representations, target_embedding], dim=-1)\n",
    "\n",
    "nonlinearity = torch.nn.functional.relu\n",
    "if fc_layers:\n",
    "    for idx, _ in enumerate(range(len(fc_layers)-1)):\n",
    "        vector = nonlinearity(fc_layers[idx](vector))\n",
    "    final_output = fc_layers[-1](vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.24 ms\n"
     ]
    }
   ],
   "source": [
    "final_output.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.93 ms\n"
     ]
    }
   ],
   "source": [
    "dot = ((user_representations * target_embedding)\n",
    "               .sum(1))\n",
    "dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 128, 64, 1]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.92 ms\n"
     ]
    }
   ],
   "source": [
    "[int(x) for x in \"256-128-64-1\".split(\"-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "time: 848 µs\n"
     ]
    }
   ],
   "source": [
    "for idx, _ in enumerate(range(len(fc_layers)-1)):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.7 ms\n"
     ]
    }
   ],
   "source": [
    "iit = list(zip(sequences.user_ids, sequences.sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_neg_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-neg-flatten-aug-28-phase\" + suffix)\n",
    "validate_pos_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-pos-flatten-aug-28-phase\" + suffix)\n",
    "\n",
    "validate_neg_flatten_vids[\"vindex\"] = validate_neg_flatten_vids[\"vindex\"]+1\n",
    "validate_pos_flatten_vids[\"vindex\"] = validate_pos_flatten_vids[\"vindex\"]+1\n",
    "\n",
    "merged_valid_vids = validate_neg_flatten_vids.groupby(\"uindex\")[\"nvindex\"].agg(list).reset_index().merge(validate_pos_flatten_vids, on=\"uindex\")\n",
    "merged_valid_vids[\"videos\"] = merged_valid_vids.apply(lambda x: x[\"nvindex\"] + [x[\"vindex\"]], axis=1)\n",
    "merged_valid_vids = merged_valid_vids.set_index(\"uindex\")\n",
    "merged_valid_vids[\"videos\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 482 µs\n"
     ]
    }
   ],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-afaf6efcbab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequences_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sequences_tensor' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "sequences_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 11.17 GiB total capacity; 9.62 GiB already allocated; 259.81 MiB free; 1.00 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-7f48296ca6a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msequences_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0muser_rp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/emb3/spotlight/spotlight/sequence/representations.py\u001b[0m in \u001b[0;36muser_representation\u001b[0;34m(self, item_sequences)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Make the embedding dimension the channel dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         sequence_embeddings = (self.item_embeddings(item_sequences)\n\u001b[0m\u001b[1;32m    403\u001b[0m                                .permute(0, 2, 1))\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# Add a trailing dimension of 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 11.17 GiB total capacity; 9.62 GiB already allocated; 259.81 MiB free; 1.00 GiB cached)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.8 ms\n"
     ]
    }
   ],
   "source": [
    "use_cuda=True\n",
    "iit = list(zip(sequences.user_ids, sequences.sequences))\n",
    "\n",
    "bs = 1024\n",
    "\n",
    "pos_uids = []\n",
    "pos_item_ids = []\n",
    "pos_scores = []\n",
    "neg_uids = []\n",
    "neg_item_ids = []\n",
    "neg_scores = []\n",
    "\n",
    "cnt=0\n",
    "\n",
    "for uid, seqs in iit:\n",
    "    cnt+=1\n",
    "    print(cnt)\n",
    "    sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)\n",
    "    user_rp = mm.user_representation(sequences_tensor)[1]\n",
    "    \n",
    "\n",
    "# for i in list(range(0, len(iit), bs)):\n",
    "#     lb, ub = i, i+bs\n",
    "#     uids, seqs = zip(*iit[lb:ub])\n",
    "#     sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)\n",
    "#     user_rp = mm.user_representation(sequences_tensor)[1]\n",
    "    \n",
    "#     for i in range(len(uids)):\n",
    "#         uid = uids[i]\n",
    "#         vids = merged_valid_vids[\"videos\"][uid]\n",
    "#         predictions = mm(fuser_rp[i].expand((len(vids), 128)), gpu(torch.from_numpy(np.array(vids).reshape(-1, 1)).long(),use_cuda)).cpu().detach().numpy()\n",
    "    \n",
    "#     user_rp= None\n",
    "#     sequences_tensor= None\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.27 ms\n"
     ]
    }
   ],
   "source": [
    "user_rp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 128])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.54 ms\n"
     ]
    }
   ],
   "source": [
    "final_user_rep[35].expand((25, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uindex\n",
       "35         [4386, 8400, 10425, 8402, 2178, 17263, 8761, 1...\n",
       "67         [15940, 1747, 8325, 14425, 7237, 11847, 17162,...\n",
       "113        [5857, 12046, 6426, 8102, 1471, 5340, 5353, 17...\n",
       "125        [8905, 6958, 5109, 118, 17193, 12712, 9036, 16...\n",
       "150        [16104, 11892, 9863, 2721, 11494, 14878, 15662...\n",
       "                                 ...                        \n",
       "1498702    [15894, 9131, 1424, 5444, 7875, 12222, 11277, ...\n",
       "1498707    [3580, 15871, 451, 12339, 13824, 12737, 997, 1...\n",
       "1498711    [3170, 5622, 6511, 15128, 6487, 8693, 10238, 1...\n",
       "1498734    [6808, 15991, 8031, 14241, 14683, 17451, 15162...\n",
       "1498783    [3352, 17060, 8419, 10223, 14741, 11400, 16829...\n",
       "Name: videos, Length: 75000, dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "#neg_vids = validate_neg_flatten_vids.merge(validate_pos_flatten_vids, on=\"uindex\").groupby(\"uindex\")[\"nvindex\"].agg(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.01 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76091"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "len(iit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67117056"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.08 ms\n"
     ]
    }
   ],
   "source": [
    "lb\n",
    "ub\n",
    "#uids, seqs = zip(*iit[lb:ub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 128])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63.1 ms\n"
     ]
    }
   ],
   "source": [
    "iit = list(zip(sequences.user_ids, sequences.sequences))\n",
    "\n",
    "sqs = sequences.sequences[0:8192]\n",
    "use_cuda=True\n",
    "sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)\n",
    "\n",
    "mm.user_representation(sequences_tensor)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 100])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.11 ms\n"
     ]
    }
   ],
   "source": [
    "sequences_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.8 ms\n"
     ]
    }
   ],
   "source": [
    "dd = dict(zip(range(len(sequences_tensor)), mm.user_representation(sequences_tensor)[1]))\n",
    "torch.stack([dd[0], dd[1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "validate_neg_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-neg-flatten-aug-28-phase\" + suffix)\n",
    "validate_pos_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-pos-flatten-aug-28-phase\" + suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uindex</th>\n",
       "      <th>nvindex</th>\n",
       "      <th>vindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>389020</td>\n",
       "      <td>2681</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389020</td>\n",
       "      <td>2724</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389020</td>\n",
       "      <td>9647</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>389020</td>\n",
       "      <td>12293</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>389020</td>\n",
       "      <td>13562</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>389020</td>\n",
       "      <td>15320</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>389020</td>\n",
       "      <td>16516</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>389020</td>\n",
       "      <td>8739</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>389020</td>\n",
       "      <td>6449</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>389020</td>\n",
       "      <td>11069</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>389020</td>\n",
       "      <td>1787</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>389020</td>\n",
       "      <td>1985</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>389020</td>\n",
       "      <td>17116</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>389020</td>\n",
       "      <td>14627</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>389020</td>\n",
       "      <td>7429</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>389020</td>\n",
       "      <td>10640</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389020</td>\n",
       "      <td>16292</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>389020</td>\n",
       "      <td>456</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>389020</td>\n",
       "      <td>14934</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>389020</td>\n",
       "      <td>3466</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>389020</td>\n",
       "      <td>5683</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>389020</td>\n",
       "      <td>7866</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>389020</td>\n",
       "      <td>10514</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>389020</td>\n",
       "      <td>822</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>389020</td>\n",
       "      <td>3473</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>389020</td>\n",
       "      <td>15353</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>389020</td>\n",
       "      <td>16223</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>389020</td>\n",
       "      <td>5522</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>389020</td>\n",
       "      <td>11658</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>389020</td>\n",
       "      <td>4717</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499970</th>\n",
       "      <td>1011390</td>\n",
       "      <td>15374</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499971</th>\n",
       "      <td>1011390</td>\n",
       "      <td>17</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499972</th>\n",
       "      <td>1011390</td>\n",
       "      <td>7685</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499973</th>\n",
       "      <td>1011390</td>\n",
       "      <td>502</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499974</th>\n",
       "      <td>1011390</td>\n",
       "      <td>4049</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499975</th>\n",
       "      <td>1011390</td>\n",
       "      <td>9743</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499976</th>\n",
       "      <td>1011390</td>\n",
       "      <td>682</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499977</th>\n",
       "      <td>1011390</td>\n",
       "      <td>7736</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499978</th>\n",
       "      <td>1011390</td>\n",
       "      <td>15539</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499979</th>\n",
       "      <td>1011390</td>\n",
       "      <td>7890</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499980</th>\n",
       "      <td>1011390</td>\n",
       "      <td>16357</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499981</th>\n",
       "      <td>1011390</td>\n",
       "      <td>2675</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499982</th>\n",
       "      <td>1011390</td>\n",
       "      <td>15588</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499983</th>\n",
       "      <td>1011390</td>\n",
       "      <td>121</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499984</th>\n",
       "      <td>1011390</td>\n",
       "      <td>11153</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499985</th>\n",
       "      <td>1011390</td>\n",
       "      <td>11832</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499986</th>\n",
       "      <td>1011390</td>\n",
       "      <td>4233</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499987</th>\n",
       "      <td>1011390</td>\n",
       "      <td>1046</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499988</th>\n",
       "      <td>1011390</td>\n",
       "      <td>14982</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499989</th>\n",
       "      <td>1011390</td>\n",
       "      <td>6759</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499990</th>\n",
       "      <td>1011390</td>\n",
       "      <td>9659</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499991</th>\n",
       "      <td>1011390</td>\n",
       "      <td>6682</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499992</th>\n",
       "      <td>1011390</td>\n",
       "      <td>12711</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499993</th>\n",
       "      <td>1011390</td>\n",
       "      <td>2691</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499994</th>\n",
       "      <td>1011390</td>\n",
       "      <td>17344</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499995</th>\n",
       "      <td>1011390</td>\n",
       "      <td>2869</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499996</th>\n",
       "      <td>1011390</td>\n",
       "      <td>8445</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499997</th>\n",
       "      <td>1011390</td>\n",
       "      <td>15587</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499998</th>\n",
       "      <td>1011390</td>\n",
       "      <td>3161</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499999</th>\n",
       "      <td>1011390</td>\n",
       "      <td>2376</td>\n",
       "      <td>17377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uindex  nvindex  vindex\n",
       "0         389020     2681   13849\n",
       "1         389020     2724   13849\n",
       "2         389020     9647   13849\n",
       "3         389020    12293   13849\n",
       "4         389020    13562   13849\n",
       "...          ...      ...     ...\n",
       "7499995  1011390     2869   17377\n",
       "7499996  1011390     8445   17377\n",
       "7499997  1011390    15587   17377\n",
       "7499998  1011390     3161   17377\n",
       "7499999  1011390     2376   17377\n",
       "\n",
       "[7500000 rows x 3 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 691 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-9a10c9e786d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vindex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.6 ms\n"
     ]
    }
   ],
   "source": [
    "gpu(torch.from_numpy(vlist[\"vindex\"][0:2].to_numpy()), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-b5ea995c38a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#np.matrix(vlist[\"vindex\"][0:2].tolist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vindex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "#np.matrix(vlist[\"vindex\"][0:2].tolist())\n",
    "np.stack(vlist[\"vindex\"][0:2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"/home/ec2-user/emb3/data/train-aug-28-phase\" + suffix\n",
    "original_train_data = pd.read_parquet(train_data_path)\n",
    "uvs = original_train_data.groupby(\"uindex\")[\"vindex\"].agg(list)\n",
    "max_sequence_len = 50\n",
    "#uvs.loc[validate_pos_flatten_vids.uindex.tolist()].apply(lambda x: len(x)).max()\n",
    "\n",
    "train_data = original_train_data[original_train_data.uindex.isin(uvs[uvs.apply(lambda x: len(x)) <= max_sequence_len].index)]\n",
    "train_data[\"vindex\"] = train_data[\"vindex\"]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "validate_neg_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-neg-flatten-aug-28-phase\" + suffix)\n",
    "validate_pos_flatten_vids = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/validate-pos-flatten-aug-28-phase\" + suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6 s\n"
     ]
    }
   ],
   "source": [
    "validation_train_data = train_data[train_data[\"uindex\"].isin(validate_pos_flatten_vids.uindex.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 927 ms\n"
     ]
    }
   ],
   "source": [
    "interactions = Interactions(validation_train_data[\"uindex\"].to_numpy(),\n",
    "            validation_train_data[\"vindex\"].to_numpy(),\n",
    "            validation_train_data[\"pct_cvt\"].to_numpy(),\n",
    "            validation_train_data[\"latest_watch_time\"].to_numpy(),\n",
    "            num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "            num_items=len(original_train_data[\"vindex\"].unique()) + 2)\n",
    "\n",
    "sequences = interactions.to_sequence(max_sequence_length=max_sequence_len, step_size=max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 580 µs\n"
     ]
    }
   ],
   "source": [
    "from spotlight.torch_utils import cpu, gpu, minibatch, set_seed, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 50])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.54 ms\n"
     ]
    }
   ],
   "source": [
    "sqs = sequences.sequences[0:2]\n",
    "use_cuda=True\n",
    "sequences_tensor = gpu(torch.from_numpy(sqs).long(),use_cuda)\n",
    "\n",
    "mm.user_representation(sequences_tensor)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 506 ms\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length=50\n",
    "sequences = interactions.to_sequence(max_sequence_length=50, step_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70982, 70982)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 182 ms\n"
     ]
    }
   ],
   "source": [
    "len(set(sequences.user_ids).intersection(validation_train_data.uindex.unique().tolist())), len(validation_train_data.uindex.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,  2037, 17460, 12020,  5345, 16440,  3443,\n",
       "        5250, 13248, 11933,  4393,  1950,  5314, 17458,  7239,  7669,\n",
       "         363, 11228, 14032,  9753, 10334], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.52 ms\n"
     ]
    }
   ],
   "source": [
    "sequences.sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "def pairs_ndcg_and_recall_score(embs):\n",
    "    suffix = os.environ['SUFFIX']\n",
    "    vindex_pairs_df = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/test-pairs-indexed-aug-28-phase\" + suffix)\n",
    "    embs_ranks = calc_embs_rank(embs)\n",
    "    number_of_videos = len(embs_ranks)\n",
    "    lookup_table = embs_ranks.values.ravel()\n",
    "    \n",
    "    rrank = vindex_pairs_df.apply(lambda r: lookup_table[r[\"v1\"] * number_of_videos + r[\"v2\"]], axis=1)\n",
    "    vindex_pairs_df[\"rrank\"] = rrank\n",
    "    \n",
    "    ndcg_vals = vindex_pairs_df.apply(\n",
    "        lambda r: (1. / np.log(r[\"rrank\"] + 1.)) * r[\"count\"], axis=1)\n",
    "    recall_vals = vindex_pairs_df.apply(lambda r: (1 if r[\"rrank\"] <= 10 else 0) * r[\"count\"] ,axis=1)\n",
    "    return ndcg_vals.mean(), recall_vals.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/emb3/spotlight/spotlight/evaluation.py:71: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  embeds_norm = np.divide(embeds, np.sqrt(np.square(embeds).sum(axis=1)).reshape(-1, 1))\n",
      "/home/ec2-user/emb3/spotlight/spotlight/evaluation.py:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "  embeds_norm = np.divide(embeds, np.sqrt(np.square(embeds).sum(axis=1)).reshape(-1, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28422729905963035, 0.05332454594795479)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "suffix = os.environ['SUFFIX']\n",
    "als_embds = pd.read_parquet(\"/home/ec2-user/emb3/data/als-embs-pandas-aug-28-phase\" + suffix)\n",
    "aa = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/video2index-pandas-aug-28-phase\" + suffix)\n",
    "videoid2index = dict(zip(aa[\"k\"], aa[\"v\"]))\n",
    "\n",
    "number_of_videos = len(videoid2index)\n",
    "embs = np.ma.masked_all((number_of_videos, 100))\n",
    "for i, row in als_embds.iterrows():\n",
    "    vindex = row[\"vindex\"]\n",
    "    if vindex != -1:\n",
    "        embs[vindex, :] = row[\"vector\"]\n",
    "pairs_ndcg_and_recall_score(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2936994845841601, 0.06328120613548437)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "model = mm\n",
    "suffix = os.environ['SUFFIX']\n",
    "aa = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/video2index-pandas-aug-28-phase\" + suffix)\n",
    "videoid2index = dict(zip(aa[\"k\"], aa[\"v\"]))\n",
    "\n",
    "model.eval()\n",
    "number_of_videos = len(videoid2index)\n",
    "with torch.no_grad():\n",
    "    raw_embeds = model.get_embeddings().detach()\n",
    "    raw_embeds = raw_embeds.cpu()\n",
    "    raw_embeds = raw_embeds.numpy()\n",
    "    embed_size = model.get_embedding_size()\n",
    "\n",
    "    embs = np.ma.masked_all((number_of_videos+10, embed_size))\n",
    "    for idx, emb in enumerate(raw_embeds):\n",
    "        #if idx in valid_ids:\n",
    "        embs[idx, :] = emb\n",
    "pairs_ndcg_and_recall_score(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /home/ec2-user/models/cnn_loss*: No such file or directory\n",
      "time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%ls /home/ec2-user/models/cnn_loss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "time: 648 µs\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "suffix = \"500K-with-3-vids\"\n",
    "train_data_path = \"/home/ec2-user/emb3/data/train-aug-28-phase\" + suffix\n",
    "original_train_data = pd.read_parquet(train_data_path)\n",
    "\n",
    "#train_data = original_train_data\n",
    "train_data = original_train_data.copy()\n",
    "train_data[\"vindex\"] = train_data[\"vindex\"]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 348 ms\n"
     ]
    }
   ],
   "source": [
    "interactions = Interactions(train_data[\"uindex\"].to_numpy(),\n",
    "            train_data[\"vindex\"].to_numpy(),\n",
    "            train_data[\"pct_cvt\"].to_numpy(),\n",
    "            train_data[\"latest_watch_time\"].to_numpy(),\n",
    "            num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "            num_items=len(original_train_data[\"vindex\"].unique()) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length=100\n",
    "min_sequence_length=1\n",
    "step_size=1\n",
    "train_seq = interactions.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                              min_sequence_length=min_sequence_length,\n",
    "                              step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Batch 0, Loss 1.008164405822754\n",
      "Here\n",
      "[Epoch 0] Batch 5000, Loss 0.4232798805832863\n",
      "[Epoch 0] Batch 10000, Loss 0.2841775295913219\n"
     ]
    }
   ],
   "source": [
    "model_alias = \",\".join([k+\"=\"+str(v) for k,v in collections.OrderedDict(hyperparameters).items()])\n",
    "model_alias = model_alias + \"__TMP\"\n",
    "tensorboard_base_dir=\"/home/ec2-user/emb3/ttest\"\n",
    "writer = SummaryWriter(log_dir='{}/{}'.format(tensorboard_base_dir, model_alias))\n",
    "\n",
    "model_store_dir= \"/home/ec2-user/emb3/models\"\n",
    "\n",
    "def notify_loss_completion(epoch_id, batch_id, loss, net, model):\n",
    "    #print(\"notify_loss_completion\")\n",
    "    writer.add_scalar(\"Batch/loss\", loss, batch_id)\n",
    "    print('[Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\n",
    "    logging.info('[Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\n",
    "\n",
    "def notify_batch_eval_completion(epoch_id, batch_id, loss, net, model):\n",
    "    #print(\"notify_batch_eval_completion\")\n",
    "#     pairs_ndcg = nn_pairs_ndcg_score(net)\n",
    "#     writer.add_scalar(\"Batch/pairs_ndcg\", pairs_ndcg, batch_id)\n",
    "#     logging.info('[Epoch {}] Batch {}, Embs NDCG = {:.4f}'.format(epoch_id, batch_id, pairs_ndcg))\n",
    "#     print('[Epoch {}] Batch {}, Embs NDCG = {:.4f}'.format(epoch_id, batch_id, pairs_ndcg))\n",
    "    print(\"Here\")\n",
    "    net.train()\n",
    "    \n",
    "def notify_epoch_completion(epoch_num, total_loss, net, model):\n",
    "    #print(\"notify_epoch_completion\")\n",
    "    writer.add_scalar(\"Epoch/loss\", total_loss, epoch_num)\n",
    "    pairs_ndcg = nn_pairs_ndcg_score(net)\n",
    "    writer.add_scalar(\"Epoch/pairs_ndcg\", pairs_ndcg, epoch_num)\n",
    "#     hit_ratio, ndcg = evaluate_hit_ratio_and_ndcg(model)\n",
    "#     writer.add_scalar(\"Epoch/HR\", hit_ratio, epoch_num)\n",
    "#     writer.add_scalar(\"Epoch/NDCG\", ndcg, epoch_num)\n",
    "    hit_ratio, ndcg = -1,-1\n",
    "    logging.info('******** [Epoch {}]  Embs NDCG {:.4f}, Hit Ratio: {:.4f}, NDCG: {:.4f}'.format(epoch_num,\n",
    "                                                                                                    pairs_ndcg,\n",
    "                                                                                                    hit_ratio,\n",
    "                                                                                                    ndcg))\n",
    "    print('******** [Epoch {}]  Embs NDCG {:.4f}, Hit Ratio: {:.4f}, NDCG: {:.4f}'.format(epoch_num,\n",
    "                                                                                                    pairs_ndcg,\n",
    "                                                                                                    hit_ratio,\n",
    "                                                                                                    ndcg))\n",
    "    torch.save(net, model_store_dir + \"/\" + model_alias + \"-\" + str(epoch_num))\n",
    "    net.train()\n",
    "\n",
    "\n",
    "os.environ[\"SUFFIX\"] = suffix\n",
    "os.environ[\"BASE_DIR\"] = \"/home/ec2-user/emb3\"\n",
    "\n",
    "writer.add_text('alias', model_alias, 0)\n",
    "\n",
    "CUDA=True\n",
    "h = hyperparameters\n",
    "random_state = np.random.RandomState(100)\n",
    "\n",
    "model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                              representation='lstm',\n",
    "                              batch_size=h['batch_size'],\n",
    "                              learning_rate=h['learning_rate'],\n",
    "                              l2=h['l2'],\n",
    "                              n_iter=h['n_iter'],\n",
    "                              embedding_dim=h['embedding_dim'],\n",
    "                              use_cuda=CUDA,\n",
    "                              random_state=random_state,\n",
    "                             notify_loss_completion=notify_loss_completion,\n",
    "                                  notify_batch_eval_completion=notify_batch_eval_completion,\n",
    "                                  notify_epoch_completion=notify_epoch_completion,\n",
    "                             log_loss_interval=5000,\n",
    "                             log_eval_interval=20000)\n",
    "\n",
    "model.fit(train_seq, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "m = torch.load(\"models/64-4-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_bpr-lr-0.001-l2-1e-05-mom-0.99-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17388, 128]), torch.Size([17389, 128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.62 ms\n"
     ]
    }
   ],
   "source": [
    "m.embedding_item.weight[1:,:].shape, m.embedding_item.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 699 µs\n"
     ]
    }
   ],
   "source": [
    "suffix = \"500K-with-3-vids\"\n",
    "os.environ[\"SUFFIX\"] = suffix\n",
    "os.environ[\"BASE_DIR\"] = \"/home/ec2-user/emb3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 150 ms\n"
     ]
    }
   ],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "\n",
    "train, test = random_train_test_split(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "model = ImplicitFactorizationModel(n_iter=15,\n",
    "                                   loss='bpr')\n",
    "model.fit(train)\n",
    "\n",
    "mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02882165588353406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.52 ms\n"
     ]
    }
   ],
   "source": [
    "mrr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 100\n",
    "\n",
    "LEARNING_RATES = [1e-3, 1e-2, 5 * 1e-2, 1e-1]\n",
    "LOSSES = ['bpr', 'hinge', 'adaptive_hinge', 'pointwise']\n",
    "BATCH_SIZE = [8, 16, 32, 256]\n",
    "EMBEDDING_DIM = [8, 16, 32, 64, 128, 256]\n",
    "N_ITER = list(range(5, 20))\n",
    "L2 = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.0]\n",
    "\n",
    "\n",
    "def sample_cnn_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'kernel_width': [3, 5, 7],\n",
    "        'num_layers': list(range(1, 10)),\n",
    "        'dilation_multiplier': [1, 2],\n",
    "        'nonlinearity': ['tanh', 'relu'],\n",
    "        'residual': [True, False]\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "        params['dilation'] = list(params['dilation_multiplier'] ** (i % 8)\n",
    "                                  for i in range(params['num_layers']))\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def sample_lstm_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.6 s\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length=200\n",
    "min_sequence_length=2\n",
    "step_size=2\n",
    "\n",
    "train_seq = train.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                              min_sequence_length=min_sequence_length,\n",
    "                              step_size=step_size)\n",
    "test_seq = test.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                        min_sequence_length=min_sequence_length,\n",
    "                        step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
