{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 590 µs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.interactions import Interactions\n",
    "import pandas as pd\n",
    "from spotlight.evaluation import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from spotlight.factorization.representations import *\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "time: 648 µs\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 913 ms\n"
     ]
    }
   ],
   "source": [
    "suffix = \"1500K-with-3-vids\"\n",
    "train_data_path = \"/home/ec2-user/emb3/data/train-aug-28-phase\" + suffix\n",
    "original_train_data = pd.read_parquet(train_data_path)\n",
    "\n",
    "#train_data = original_train_data\n",
    "train_data = original_train_data.copy()\n",
    "train_data[\"vindex\"] = train_data[\"vindex\"]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17538, 17539)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 376 ms\n"
     ]
    }
   ],
   "source": [
    "len(original_train_data[\"vindex\"].unique()), train_data[\"vindex\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 870 ms\n"
     ]
    }
   ],
   "source": [
    "interactions = Interactions(train_data[\"uindex\"].to_numpy(),\n",
    "            train_data[\"vindex\"].to_numpy(),\n",
    "            train_data[\"pct_cvt\"].to_numpy(),\n",
    "            train_data[\"latest_watch_time\"].to_numpy(),\n",
    "            num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "            num_items=(len(original_train_data[\"vindex\"].unique()) + 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length=100\n",
    "min_sequence_length=1\n",
    "step_size=1\n",
    "train_seq = interactions.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                              min_sequence_length=min_sequence_length,\n",
    "                              step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "uvs = original_train_data.groupby(\"uindex\")[\"vindex\"].agg(list)\n",
    "train_data = original_train_data[original_train_data.uindex.isin(uvs[uvs.apply(lambda x: len(x)) <= 50].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17312359, 24421579)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "#len(uvs[uvs.apply(lambda x: len(x)) <= 50]), len(uvs)\n",
    "len(train_data[train_data.uindex.isin(uvs[uvs.apply(lambda x: len(x)) <= 50].index)]), len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Batch 0, Loss 1.008164405822754\n",
      "Here\n",
      "[Epoch 0] Batch 5000, Loss 0.4232798805832863\n",
      "[Epoch 0] Batch 10000, Loss 0.2841775295913219\n",
      "[Epoch 0] Batch 15000, Loss 0.2548156420081854\n",
      "[Epoch 0] Batch 20000, Loss 0.2421273371309042\n",
      "Here\n",
      "[Epoch 0] Batch 25000, Loss 0.2349102160125971\n",
      "[Epoch 0] Batch 30000, Loss 0.2297738703995943\n",
      "Epoch 0: loss 8711.137982949615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/emb3/spotlight/spotlight/evaluation.py:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "  embeds_norm = np.divide(embeds, np.sqrt(np.square(embeds).sum(axis=1)).reshape(-1, 1))\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'loss': \"adaptive_hinge\",\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 1e-3,\n",
    "    'l2': 1e-06,\n",
    "    'n_iter': 30,\n",
    "    'embedding_dim': 64\n",
    "}\n",
    "\n",
    "model_alias = \",\".join([k+\"=\"+str(v) for k,v in collections.OrderedDict(hyperparameters).items()])\n",
    "model_alias = model_alias + \"__TMP\"\n",
    "tensorboard_base_dir=\"/home/ec2-user/emb3/ttest\"\n",
    "writer = SummaryWriter(log_dir='{}/{}'.format(tensorboard_base_dir, model_alias))\n",
    "\n",
    "model_store_dir= \"/home/ec2-user/emb3/models\"\n",
    "\n",
    "def notify_loss_completion(epoch_id, batch_id, loss, net, model):\n",
    "    #print(\"notify_loss_completion\")\n",
    "    writer.add_scalar(\"Batch/loss\", loss, batch_id)\n",
    "    print('[Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\n",
    "    logging.info('[Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\n",
    "\n",
    "def notify_batch_eval_completion(epoch_id, batch_id, loss, net, model):\n",
    "    #print(\"notify_batch_eval_completion\")\n",
    "#     pairs_ndcg = nn_pairs_ndcg_score(net)\n",
    "#     writer.add_scalar(\"Batch/pairs_ndcg\", pairs_ndcg, batch_id)\n",
    "#     logging.info('[Epoch {}] Batch {}, Embs NDCG = {:.4f}'.format(epoch_id, batch_id, pairs_ndcg))\n",
    "#     print('[Epoch {}] Batch {}, Embs NDCG = {:.4f}'.format(epoch_id, batch_id, pairs_ndcg))\n",
    "    print(\"Here\")\n",
    "    net.train()\n",
    "    \n",
    "def notify_epoch_completion(epoch_num, total_loss, net, model):\n",
    "    #print(\"notify_epoch_completion\")\n",
    "    writer.add_scalar(\"Epoch/loss\", total_loss, epoch_num)\n",
    "    pairs_ndcg = nn_pairs_ndcg_score(net)\n",
    "    writer.add_scalar(\"Epoch/pairs_ndcg\", pairs_ndcg, epoch_num)\n",
    "#     hit_ratio, ndcg = evaluate_hit_ratio_and_ndcg(model)\n",
    "#     writer.add_scalar(\"Epoch/HR\", hit_ratio, epoch_num)\n",
    "#     writer.add_scalar(\"Epoch/NDCG\", ndcg, epoch_num)\n",
    "    hit_ratio, ndcg = -1,-1\n",
    "    logging.info('******** [Epoch {}]  Embs NDCG {:.4f}, Hit Ratio: {:.4f}, NDCG: {:.4f}'.format(epoch_num,\n",
    "                                                                                                    pairs_ndcg,\n",
    "                                                                                                    hit_ratio,\n",
    "                                                                                                    ndcg))\n",
    "    print('******** [Epoch {}]  Embs NDCG {:.4f}, Hit Ratio: {:.4f}, NDCG: {:.4f}'.format(epoch_num,\n",
    "                                                                                                    pairs_ndcg,\n",
    "                                                                                                    hit_ratio,\n",
    "                                                                                                    ndcg))\n",
    "    torch.save(net, model_store_dir + \"/\" + model_alias + \"-\" + str(epoch_num))\n",
    "    net.train()\n",
    "\n",
    "\n",
    "os.environ[\"SUFFIX\"] = suffix\n",
    "os.environ[\"BASE_DIR\"] = \"/home/ec2-user/emb3\"\n",
    "\n",
    "writer.add_text('alias', model_alias, 0)\n",
    "\n",
    "CUDA=True\n",
    "h = hyperparameters\n",
    "random_state = np.random.RandomState(100)\n",
    "\n",
    "model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                              representation='lstm',\n",
    "                              batch_size=h['batch_size'],\n",
    "                              learning_rate=h['learning_rate'],\n",
    "                              l2=h['l2'],\n",
    "                              n_iter=h['n_iter'],\n",
    "                              embedding_dim=h['embedding_dim'],\n",
    "                              use_cuda=CUDA,\n",
    "                              random_state=random_state,\n",
    "                             notify_loss_completion=notify_loss_completion,\n",
    "                                  notify_batch_eval_completion=notify_batch_eval_completion,\n",
    "                                  notify_epoch_completion=notify_epoch_completion,\n",
    "                             log_loss_interval=5000,\n",
    "                             log_eval_interval=20000)\n",
    "\n",
    "model.fit(train_seq, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "m = torch.load(\"models/64-4-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_bpr-lr-0.001-l2-1e-05-mom-0.99-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17388, 128]), torch.Size([17389, 128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.62 ms\n"
     ]
    }
   ],
   "source": [
    "m.embedding_item.weight[1:,:].shape, m.embedding_item.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 699 µs\n"
     ]
    }
   ],
   "source": [
    "suffix = \"500K-with-3-vids\"\n",
    "os.environ[\"SUFFIX\"] = suffix\n",
    "os.environ[\"BASE_DIR\"] = \"/home/ec2-user/emb3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 150 ms\n"
     ]
    }
   ],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "\n",
    "train, test = random_train_test_split(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "model = ImplicitFactorizationModel(n_iter=15,\n",
    "                                   loss='bpr')\n",
    "model.fit(train)\n",
    "\n",
    "mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02882165588353406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.52 ms\n"
     ]
    }
   ],
   "source": [
    "mrr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 100\n",
    "\n",
    "LEARNING_RATES = [1e-3, 1e-2, 5 * 1e-2, 1e-1]\n",
    "LOSSES = ['bpr', 'hinge', 'adaptive_hinge', 'pointwise']\n",
    "BATCH_SIZE = [8, 16, 32, 256]\n",
    "EMBEDDING_DIM = [8, 16, 32, 64, 128, 256]\n",
    "N_ITER = list(range(5, 20))\n",
    "L2 = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.0]\n",
    "\n",
    "\n",
    "def sample_cnn_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'kernel_width': [3, 5, 7],\n",
    "        'num_layers': list(range(1, 10)),\n",
    "        'dilation_multiplier': [1, 2],\n",
    "        'nonlinearity': ['tanh', 'relu'],\n",
    "        'residual': [True, False]\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "        params['dilation'] = list(params['dilation_multiplier'] ** (i % 8)\n",
    "                                  for i in range(params['num_layers']))\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def sample_lstm_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.6 s\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length=200\n",
    "min_sequence_length=2\n",
    "step_size=2\n",
    "\n",
    "train_seq = train.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                              min_sequence_length=min_sequence_length,\n",
    "                              step_size=step_size)\n",
    "test_seq = test.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                        min_sequence_length=min_sequence_length,\n",
    "                        step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
