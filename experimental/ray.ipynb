{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>pairs_ndcg</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.567488e+09</td>\n",
       "      <td>32</td>\n",
       "      <td>0.285385</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.99-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.567467e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.97-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.567456e+09</td>\n",
       "      <td>47</td>\n",
       "      <td>0.281562</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.9-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.567483e+09</td>\n",
       "      <td>63</td>\n",
       "      <td>0.280697</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.95-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.567475e+09</td>\n",
       "      <td>54</td>\n",
       "      <td>0.278612</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.95-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.567483e+09</td>\n",
       "      <td>54</td>\n",
       "      <td>0.278262</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.98-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.567470e+09</td>\n",
       "      <td>32</td>\n",
       "      <td>0.277345</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.96-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.567490e+09</td>\n",
       "      <td>11</td>\n",
       "      <td>0.277079</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.999-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.567455e+09</td>\n",
       "      <td>45</td>\n",
       "      <td>0.276810</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.95-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-False-adamw=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.567440e+09</td>\n",
       "      <td>38</td>\n",
       "      <td>0.273613</td>\n",
       "      <td>32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.92-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-False-adamw=None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  Epoch  pairs_ndcg  \\\n",
       "32  1.567488e+09  32     0.285385     \n",
       "22  1.567467e+09  22     0.283133     \n",
       "47  1.567456e+09  47     0.281562     \n",
       "63  1.567483e+09  63     0.280697     \n",
       "54  1.567475e+09  54     0.278612     \n",
       "54  1.567483e+09  54     0.278262     \n",
       "32  1.567470e+09  32     0.277345     \n",
       "11  1.567490e+09  11     0.277079     \n",
       "45  1.567455e+09  45     0.276810     \n",
       "38  1.567440e+09  38     0.273613     \n",
       "\n",
       "                                                                                                                                    run_name  \n",
       "32  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.99-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None   \n",
       "22  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.97-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None   \n",
       "47  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.9-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-True-adamw=None    \n",
       "63  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.95-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-True-adamw=None   \n",
       "54  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.95-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None   \n",
       "54  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.98-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None   \n",
       "32  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.96-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None   \n",
       "11  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.999-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None  \n",
       "45  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.95-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-False-adamw=None  \n",
       "38  32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.92-smpl-1.0-ng-5-bt-1024-drp-None-amsgrad-False-adamw=None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import csv\n",
    "import errno\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorboard.backend.event_processing import plugin_event_multiplexer as event_multiplexer  # pylint: disable=line-too-long\n",
    "\n",
    "\n",
    "# Control downsampling: how many scalar data do we keep for each run/tag\n",
    "# combination?\n",
    "SIZE_GUIDANCE = {'scalars': 1000}\n",
    "\n",
    "\n",
    "def extract_scalars(multiplexer, run, tag):\n",
    "  \"\"\"Extract tabular data from the scalars at a given run and tag.\n",
    "  The result is a list of 3-tuples (wall_time, step, value).\n",
    "  \"\"\"\n",
    "  tensor_events = multiplexer.Tensors(run, tag)\n",
    "  return [\n",
    "      (event.wall_time, event.step, tf.make_ndarray(event.tensor_proto).item())\n",
    "      for event in tensor_events\n",
    "  ]\n",
    "\n",
    "\n",
    "def create_multiplexer(logdir):\n",
    "  multiplexer = event_multiplexer.EventMultiplexer(\n",
    "      tensor_size_guidance=SIZE_GUIDANCE)\n",
    "  multiplexer.AddRunsFromDirectory(logdir)\n",
    "  multiplexer.Reload()\n",
    "  return multiplexer\n",
    "\n",
    "\n",
    "def export_scalars(multiplexer, run, tag, filepath, write_headers=True):\n",
    "  data = extract_scalars(multiplexer, run, tag)\n",
    "  with open(filepath, 'w') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    if write_headers:\n",
    "      writer.writerow(('wall_time', 'step', 'value'))\n",
    "    for row in data:\n",
    "      writer.writerow(row)\n",
    "\n",
    "\n",
    "NON_ALPHABETIC = re.compile('[^A-Za-z0-9_]')\n",
    "\n",
    "def munge_filename(name):\n",
    "  \"\"\"Remove characters that might not be safe in a filename.\"\"\"\n",
    "  return NON_ALPHABETIC.sub('_', name)\n",
    "\n",
    "\n",
    "def mkdir_p(directory):\n",
    "  try:\n",
    "    os.makedirs(directory)\n",
    "  except OSError as e:\n",
    "    if not (e.errno == errno.EEXIST and os.path.isdir(directory)):\n",
    "      raise\n",
    "    \n",
    "logdir = '/home/ec2-user/emb3/runs'\n",
    "output_dir = '//home/ec2-user/emb3/csv_output'\n",
    "mkdir_p(output_dir)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "multiplexer = create_multiplexer(logdir)\n",
    "\n",
    "runs = list(multiplexer.Runs().keys())\n",
    "\n",
    "tmpl = []\n",
    "for i in range(len(runs)):\n",
    "    try:\n",
    "        data = extract_scalars(multiplexer, runs[i], \"Epoch/pairs_ndcg\")\n",
    "        ddf =  pd.DataFrame(data, columns=[\"timestamp\", \"Epoch\", \"pairs_ndcg\"])\n",
    "        ddf[\"run_name\"] = runs[i]\n",
    "        tmpl.append(ddf)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "all_vals = pd.concat(tmpl)\n",
    "all_vals[all_vals.groupby(\"run_name\")[\"pairs_ndcg\"].transform(max) == all_vals[\"pairs_ndcg\"]].sort_values(by=\"pairs_ndcg\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/emb3/models/32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.99-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None-32\n"
     ]
    }
   ],
   "source": [
    "%ls ~/emb3/models/32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.99-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"/home/ec2-user/emb3/models/32-3-bpr-MLP-suf-500K-with-3-vids-loss-adaptive_hinge-lr-0.001-l2-1e-05-mom-0.99-smpl-1.0-ng-3-bt-1024-drp-None-amsgrad-True-adamw=None-32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 472 ms\n"
     ]
    }
   ],
   "source": [
    "suffix = \"500K-with-3-vids\"\n",
    "neg_data_path  = \"data/validate-neg-flatten-aug-28-phase\" + suffix\n",
    "pos_data_path = \"data/validate-pos-flatten-aug-28-phase\" + suffix\n",
    "\n",
    "validate_neg_flatten_vids = pd.read_parquet(neg_data_path)\n",
    "validate_pos_flatten_vids = pd.read_parquet(pos_data_path)\n",
    "\n",
    "evaluate_data = [validate_pos_flatten_vids[\"uindex\"].to_numpy(),\n",
    "                     validate_pos_flatten_vids[\"vindex\"].to_numpy(),\n",
    "                     validate_neg_flatten_vids[\"uindex\"].to_numpy(),\n",
    "                     validate_neg_flatten_vids[\"nvindex\"].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embedding_user): Embedding(500044, 64)\n",
       "  (embedding_item): Embedding(17389, 64)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (affine_output): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.64 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "use_cuda=True\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "def eval_results_in_batch(serve_model,\n",
    "                          test_users,\n",
    "                          test_items,\n",
    "                          batch_size=1024):\n",
    "    total_size = len(test_users)\n",
    "    tmp_ranges = np.arange(0, total_size + batch_size, batch_size)\n",
    "    lower_indices = tmp_ranges[:-1]\n",
    "    upper_indices = tmp_ranges[1:]\n",
    "    subsets = []\n",
    "    for i in range(len(lower_indices)):\n",
    "        subset_users = test_users[lower_indices[i]:upper_indices[i]]\n",
    "        subset_items = test_items[lower_indices[i]:upper_indices[i]]\n",
    "        if len(subset_users) > 0:\n",
    "            subsets.append(serve_model(subset_users, subset_items))\n",
    "    return torch.cat(subsets, 0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_users, test_items = torch.LongTensor(evaluate_data[0]), torch.LongTensor(evaluate_data[1])\n",
    "    negative_users, negative_items = torch.LongTensor(evaluate_data[2]), torch.LongTensor(evaluate_data[3])\n",
    "    if use_cuda is True:\n",
    "        test_users = test_users.cuda()\n",
    "        test_items = test_items.cuda()\n",
    "        negative_users = negative_users.cuda()\n",
    "        negative_items = negative_items.cuda()\n",
    "    test_scores = eval_results_in_batch(model, test_users, test_items, batch_size=1024 * 3)\n",
    "    negative_scores = eval_results_in_batch(model, negative_users, negative_items, batch_size=1024 * 3)\n",
    "    if use_cuda is True:\n",
    "        test_users = test_users.cpu()\n",
    "        test_items = test_items.cpu()\n",
    "        test_scores = test_scores.cpu()\n",
    "        negative_users = negative_users.cpu()\n",
    "        negative_items = negative_items.cpu()\n",
    "        negative_scores = negative_scores.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "from spotlight.evaluation import MetronAtK\n",
    "metron = MetronAtK(top_k=10)\n",
    "\n",
    "metron.subjects = [test_users.data.view(-1).tolist(),\n",
    "                                     test_items.data.view(-1).tolist(),\n",
    "                                     test_scores.data.view(-1).tolist(),\n",
    "                                     negative_users.data.view(-1).tolist(),\n",
    "                                     negative_items.data.view(-1).tolist(),\n",
    "                                     negative_scores.data.view(-1).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "from spotlight.interactions import Interactions\n",
    "train_data_path = \"data/train-aug-28-phase\" + suffix\n",
    "original_train_data = pd.read_parquet(train_data_path)\n",
    "train_data = original_train_data\n",
    "interactions = Interactions(train_data[\"uindex\"].to_numpy(),\n",
    "            train_data[\"vindex\"].to_numpy(),\n",
    "            train_data[\"pct_cvt\"].to_numpy(),\n",
    "            train_data[\"latest_watch_time\"].to_numpy(),\n",
    "            num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "            num_items=len(original_train_data[\"vindex\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "0 is used as an item id, conflicting with the sequence padding value.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-66dcd93127a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msq_interactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/emb3/spotlight/spotlight/interactions.py\u001b[0m in \u001b[0;36mto_sequence\u001b[0;34m(self, max_sequence_length, min_sequence_length, step_size)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             raise ValueError('0 is used as an item id, conflicting '\n\u001b[0m\u001b[1;32m    228\u001b[0m                              'with the sequence padding value.')\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is used as an item id, conflicting with the sequence padding value."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.7 ms\n"
     ]
    }
   ],
   "source": [
    "sq_interactions = interactions.to_sequence(max_sequence_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/emb3/spotlight/spotlight/evaluation.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lambda x: math.log(2) / math.log(1 + x))  # the rank starts from 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9129733333333333, 0.6774019496519258)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "hit_ratio, ndcg = metron.cal_hit_ratio(), metron.cal_ndcg()\n",
    "hit_ratio, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 547 µs\n"
     ]
    }
   ],
   "source": [
    "from spotlight.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/emb3/spotlight/spotlight/evaluation.py:71: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  embeds_norm = np.divide(embeds, np.sqrt(np.square(embeds).sum(axis=1)).reshape(-1, 1))\n",
      "/home/ec2-user/emb3/spotlight/spotlight/evaluation.py:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "  embeds_norm = np.divide(embeds, np.sqrt(np.square(embeds).sum(axis=1)).reshape(-1, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2869818003525584"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"BASE_DIR\"] = \"/home/ec2-user/emb3\"\n",
    "os.environ[\"SUFFIX\"] = \"500K-with-3-vids\"\n",
    "aa = pd.read_parquet(os.environ['BASE_DIR'] + \"/data/video2index-pandas-aug-28-phase\" + suffix)\n",
    "videoid2index = dict(zip(aa[\"k\"], aa[\"v\"]))\n",
    "als_embds = pd.read_parquet(\"/home/ec2-user/emb3/data/als-embs-pandas-aug-28-phase\" + suffix)\n",
    "number_of_videos = len(videoid2index)\n",
    "embs = np.ma.masked_all((number_of_videos, 100))\n",
    "for i, row in als_embds.iterrows():\n",
    "    vindex = row[\"vindex\"]\n",
    "    if vindex != -1:\n",
    "        embs[vindex, :] = row[\"vector\"]\n",
    "pairs_ndcg_score(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/emb3/spotlight/spotlight/evaluation.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lambda x: math.log(2) / math.log(1 + x))  # the rank starts from 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9171066666666666, 0.7022161946587601)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "number_of_videos = len(videoid2index)\n",
    "aembs = np.zeros((number_of_videos, 100))\n",
    "for i, row in als_embds.iterrows():\n",
    "    vindex = row[\"vindex\"]\n",
    "    aembs[vindex, :] = row[\"vector\"]\n",
    "    \n",
    "# evaluate_data = validation_data\n",
    "test_users, test_items = evaluate_data[0], evaluate_data[1]\n",
    "negative_users, negative_items = evaluate_data[2], evaluate_data[3]\n",
    "\n",
    "suffix = os.environ[\"SUFFIX\"]\n",
    "train_data_path = \"data/train-aug-28-phase\" + suffix\n",
    "train_regr_dataset = pd.read_parquet(train_data_path)\n",
    "\n",
    "uniq_test_users = list(set(test_users))\n",
    "test_users_vids = train_regr_dataset[train_regr_dataset[\"uindex\"].isin(uniq_test_users)].groupby(\"uindex\")[\"vindex\"].agg(list)\n",
    "user_avg_vid_embs = test_users_vids.apply(lambda x: aembs[x].mean(axis=0))\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sims(a,b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))\n",
    "\n",
    "pos_scores = []\n",
    "for tu, ti in zip(test_users, test_items):\n",
    "    pos_scores.append(cosine_sims(user_avg_vid_embs[tu], aembs[ti]))\n",
    "    \n",
    "neg_scores = []\n",
    "for tu, ti in zip(negative_users, negative_items):\n",
    "    neg_scores.append(cosine_sims(user_avg_vid_embs[tu], aembs[ti]))\n",
    "    \n",
    "metron = MetronAtK(top_k=10)\n",
    "\n",
    "metron.subjects = [test_users.tolist(),\n",
    "                     test_items.tolist(),\n",
    "                     pos_scores,\n",
    "                     negative_users.tolist(),\n",
    "                     negative_items.tolist(),\n",
    "                     neg_scores]\n",
    "hit_ratio, ndcg = metron.cal_hit_ratio(), metron.cal_ndcg()\n",
    "hit_ratio, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.1872), tensor(50.8512))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.41 ms\n"
     ]
    }
   ],
   "source": [
    "negative_scores.mean(), test_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "import os\n",
    "\n",
    "os.environ['SUFFIX']=\"500K-with-3-vids\"\n",
    "os.environ['BASE_DIR']=\"/home/ec2-user/emb3\"\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.interactions import Interactions\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from spotlight.factorization.representations import *\n",
    "import os\n",
    "from spotlight.evaluation import *\n",
    "from spotlight.evaluation import mrr_score\n",
    "\n",
    "def ray_train(input_config, reporter):\n",
    "    if 'SUFFIX' in os.environ:\n",
    "        suffix = os.environ['SUFFIX']\n",
    "    else:\n",
    "        suffix = \"1\"\n",
    "    if 'LOSS' in input_config:\n",
    "        loss = input_config['LOSS']\n",
    "    else:\n",
    "        loss=\"bpr\"\n",
    "\n",
    "    if 'LR' in input_config:\n",
    "        lr = float(input_config['LR'])\n",
    "    else:\n",
    "        lr=1e-3\n",
    "\n",
    "    if 'L2' in input_config:\n",
    "        l2 = float(input_config['L2'])\n",
    "    else:\n",
    "        l2=1e-5\n",
    "\n",
    "    if 'MOM' in input_config:\n",
    "        mom = float(input_config['MOM'])\n",
    "    else:\n",
    "        mom=0.9\n",
    "\n",
    "    if 'SAMPLE' in input_config:\n",
    "        train_sample = float(input_config['SAMPLE'])\n",
    "    else:\n",
    "        train_sample = 1.0\n",
    "\n",
    "    if 'NEGSAMPLES' in input_config:\n",
    "        num_negative_samples = int(input_config['NEGSAMPLES'])\n",
    "    else:\n",
    "        num_negative_samples = 5\n",
    "\n",
    "\n",
    "    if 'BATCH' in input_config:\n",
    "        batch_size = int(input_config['BATCH'])\n",
    "    else:\n",
    "        batch_size=1024\n",
    "\n",
    "    dropout = None\n",
    "    if 'DROPOUT' in input_config and input_config['DROPOUT']:\n",
    "        dropout = float(input_config['DROPOUT'])\n",
    "\n",
    "    net_conf = \"32-3-bpr-MLP\"\n",
    "    if 'NETCONG' in input_config and input_config['NETCONG']:\n",
    "        net_conf = input_config['NETCONG']\n",
    "\n",
    "    betas=(mom, 0.999)\n",
    "    use_cuda=True\n",
    "\n",
    "    tensorboard_base_dir=\"runs\"\n",
    "    model_alias = \"{}-suf-{}-loss-{}-lr-{}-l2-{}-mom-{}-smpl-{}-ng-{}-bt-{}-drp-{}-ray\".format(net_conf, suffix, loss, lr, l2, \n",
    "                                                                                          mom, train_sample,\n",
    "                                                                                          num_negative_samples,\n",
    "                                                                                         batch_size,\n",
    "                                                                                                        dropout)\n",
    "    model_store_dir=\"/home/ec2-user/emb3/models\"\n",
    "    n_iters=30\n",
    "    #loss=\"adaptive_hinge\"\n",
    "\n",
    "    log_loss_interval=100\n",
    "    log_eval_interval=5000\n",
    "    #train_data_path = \"s3a://tubi-playground-production/smistry/emb3/train-aug-28-phase1\"\n",
    "    train_data_path = os.environ['BASE_DIR'] + \"/data/train-aug-28-phase\" + suffix\n",
    "\n",
    "    \n",
    "    original_train_data = pd.read_parquet(train_data_path)\n",
    "    writer = SummaryWriter(log_dir='{}/{}'.format(tensorboard_base_dir, model_alias))\n",
    "    writer.add_text('alias', model_alias, 0)\n",
    "\n",
    "    def notify_loss_completion(epoch_id, batch_id, loss, net, model):\n",
    "        #print(\"notify_loss_completion\")\n",
    "        writer.add_scalar(\"Batch/loss\", loss, batch_id)\n",
    "        reporter(mean_accuracy=1-loss, timesteps_total=int(batch_id/log_loss_interval), checkpoint=model_alias)\n",
    "\n",
    "    def notify_batch_eval_completion(epoch_id, batch_id, loss, net, model):\n",
    "        #print(\"notify_batch_eval_completion\")\n",
    "        pairs_ndcg = nn_pairs_ndcg_score(net)\n",
    "        writer.add_scalar(\"Batch/pairs_ndcg\", pairs_ndcg, batch_id)\n",
    "\n",
    "\n",
    "    def notify_epoch_completion(epoch_num, total_loss, net, model):\n",
    "        #print(\"notify_epoch_completion\")\n",
    "        writer.add_scalar(\"Epoch/loss\", total_loss, epoch_num)\n",
    "        pairs_ndcg = nn_pairs_ndcg_score(net)\n",
    "        writer.add_scalar(\"Epoch/pairs_ndcg\", pairs_ndcg, epoch_num)\n",
    "    #     hit_ratio, ndcg = evaluate_hit_ratio_and_ndcg(model)\n",
    "    #     writer.add_scalar(\"Epoch/HR\", hit_ratio, epoch_num)\n",
    "    #     writer.add_scalar(\"Epoch/NDCG\", ndcg, epoch_num)\n",
    "        hit_ratio, ndcg = -1,-1\n",
    "        torch.save(net, model_store_dir + \"/\" + model_alias + \"-\" + str(epoch_num))\n",
    "\n",
    "    num_users=len(original_train_data[\"uindex\"].unique())\n",
    "    num_items=len(original_train_data[\"vindex\"].unique())\n",
    "\n",
    "    train_data = original_train_data.sample(frac=train_sample)\n",
    "\n",
    "    interactions = Interactions(train_data[\"uindex\"].to_numpy(),\n",
    "                train_data[\"vindex\"].to_numpy(),\n",
    "                train_data[\"pct_cvt\"].to_numpy(),\n",
    "                train_data[\"latest_watch_time\"].to_numpy(),\n",
    "                num_users=len(original_train_data[\"uindex\"].unique()),\n",
    "                num_items=len(original_train_data[\"vindex\"].unique()))\n",
    "\n",
    "    if \"-\" in net_conf:\n",
    "        args = net_conf.split(\"-\")\n",
    "        config = {\n",
    "              \"factor_size\": int(args[0]),\n",
    "              \"num_layers\": int(args[1]),\n",
    "              \"loss_type\": args[2],\n",
    "              \"model_type\": args[3],\n",
    "            \"num_users\": num_users,\n",
    "            \"num_items\": num_items,\n",
    "        }\n",
    "        if dropout:\n",
    "            config[\"dropout\"] = dropout\n",
    "\n",
    "        num_layers = int(args[1])\n",
    "        factor_size = int(args[0])\n",
    "        config[\"layers\"] = [4 * factor_size] + [factor_size * (2 ** i) for i in range(num_layers - 1, -1, -1)]\n",
    "        config[\"latent_dim\"] = 2 * factor_size\n",
    "        writer.add_text('config', str(config), 0)\n",
    "\n",
    "        rep = MLP(config)\n",
    "    else:\n",
    "        rep = None\n",
    "\n",
    "    model = ImplicitFactorizationModel(n_iter=n_iters,\n",
    "                                       loss=loss,\n",
    "                                      notify_loss_completion=notify_loss_completion,\n",
    "                                      notify_batch_eval_completion=notify_batch_eval_completion,\n",
    "                                      notify_epoch_completion=notify_epoch_completion,\n",
    "                                      log_loss_interval=log_loss_interval,\n",
    "                                      log_eval_interval=log_eval_interval,\n",
    "                                      betas=betas,\n",
    "                                      learning_rate=lr,\n",
    "                                      batch_size=batch_size,\n",
    "                                      random_state=np.random.RandomState(2),\n",
    "                                      num_negative_samples=num_negative_samples,\n",
    "                                      l2=l2,\n",
    "                                      use_cuda=use_cuda,\n",
    "                                      representation=rep)\n",
    "    model.fit(interactions)\n",
    "    \n",
    "    \n",
    "NUM_GPUS=8\n",
    "ray.init(ignore_reinit_error=True, num_gpus=NUM_GPUS)\n",
    "\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "\n",
    "exp_config = {\n",
    "    \"LOSS\": tune.grid_search([\"adaptive_hinge\"]),\n",
    "    \"LR\": tune.grid_search([1e-3, 1e-4, 1e-2, 0.005]),\n",
    "    \"L2\": tune.grid_search([1e-5, 1e-8, 1e-10]),\n",
    "    \"DROPOUT\": tune.grid_search([0.1,0.2,0.4,0.5]),\n",
    "    \"MOM\": tune.grid_search([0.9,0.92,0.95,0.8]),\n",
    "    \"NEGSAMPLES\": tune.grid_search([5, 3, 10])\n",
    "}\n",
    "\n",
    "configuration = tune.Experiment(\n",
    "    \"check_for_500K_3_vids\",\n",
    "    run=ray_train,\n",
    "    num_samples=1,\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    stop={\"mean_accuracy\": 0.95},  # TODO: Part 1\n",
    "    config=exp_config\n",
    ")\n",
    "\n",
    "import sys\n",
    "hyperband = AsyncHyperBandScheduler(\n",
    "    time_attr='timesteps_total',\n",
    "    reward_attr='mean_accuracy')\n",
    "trials = tune.run_experiments(configuration, scheduler=hyperband, verbose=True, reuse_actors=True)\n",
    "\n",
    "def get_sorted_trials(trial_list, metric):\n",
    "    return sorted(trial_list, key=lambda trial: trial.last_result.get(metric, 0), reverse=True)\n",
    "  \n",
    "sorted_trials = get_sorted_trials(trials, metric=\"mean_accuracy\")\n",
    "print(str([(x.last_result.get(\"mean_accuracy\", 0),  x.last_result.get(\"iterations_since_restore\"), x) for x in sorted_trials]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Implements AdamW algorithm.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The original Adam algorithm was proposed in `Adam: A Method for Stochastic Optimization`_.\u001b[0m\n",
       "\u001b[0;34m    The AdamW variant was proposed in `Decoupled Weight Decay Regularization`_.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Arguments:\u001b[0m\n",
       "\u001b[0;34m        params (iterable): iterable of parameters to optimize or dicts defining\u001b[0m\n",
       "\u001b[0;34m            parameter groups\u001b[0m\n",
       "\u001b[0;34m        lr (float, optional): learning rate (default: 1e-3)\u001b[0m\n",
       "\u001b[0;34m        betas (Tuple[float, float], optional): coefficients used for computing\u001b[0m\n",
       "\u001b[0;34m            running averages of gradient and its square (default: (0.9, 0.999))\u001b[0m\n",
       "\u001b[0;34m        eps (float, optional): term added to the denominator to improve\u001b[0m\n",
       "\u001b[0;34m            numerical stability (default: 1e-8)\u001b[0m\n",
       "\u001b[0;34m        weight_decay (float, optional): weight decay coefficient (default: 1e-2)\u001b[0m\n",
       "\u001b[0;34m        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\u001b[0m\n",
       "\u001b[0;34m            algorithm from the paper `On the Convergence of Adam and Beyond`_\u001b[0m\n",
       "\u001b[0;34m            (default: False)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. _Adam\\: A Method for Stochastic Optimization:\u001b[0m\n",
       "\u001b[0;34m        https://arxiv.org/abs/1412.6980\u001b[0m\n",
       "\u001b[0;34m    .. _Decoupled Weight Decay Regularization:\u001b[0m\n",
       "\u001b[0;34m        https://arxiv.org/abs/1711.05101\u001b[0m\n",
       "\u001b[0;34m    .. _On the Convergence of Adam and Beyond:\u001b[0m\n",
       "\u001b[0;34m        https://openreview.net/forum?id=ryQu7f-RZ\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid learning rate: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid epsilon value: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid beta parameter at index 0: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid beta parameter at index 1: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdefaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amsgrad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Performs a single optimization step.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Arguments:\u001b[0m\n",
       "\u001b[0;34m            closure (callable, optional): A closure that reevaluates the model\u001b[0m\n",
       "\u001b[0;34m                and returns the loss.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Perform stepweight decay\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Perform optimization step\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adam does not support sparse gradients, please consider SparseAdam instead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mamsgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amsgrad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# State initialization\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Exponential moving average of gradient values\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg_sq'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;31m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_exp_avg_sq'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg_sq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mmax_exp_avg_sq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_exp_avg_sq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Use the max. for normalizing running avg. of gradient\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/pytorch_p36/lib/python3.7/site-packages/torch/optim/adamw.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??optim.AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
